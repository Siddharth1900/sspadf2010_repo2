{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"factoryName": {
			"type": "string",
			"metadata": "Data Factory name",
			"defaultValue": "sspadf2010"
		}
	},
	"variables": {
		"factoryId": "[concat('Microsoft.DataFactory/factories/', parameters('factoryName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('factoryName'), '/NewBranch')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_inputemp_sample",
								"type": "DatasetReference"
							},
							"name": "emp"
						},
						{
							"dataset": {
								"referenceName": "ds_inputdept_sample",
								"type": "DatasetReference"
							},
							"name": "dept"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_sinkoutput2_csv",
								"type": "DatasetReference"
							},
							"name": "joinsink"
						},
						{
							"dataset": {
								"referenceName": "ds_sinkoutput2_csv",
								"type": "DatasetReference"
							},
							"name": "aggregatesink"
						}
					],
					"transformations": [
						{
							"name": "aggregate1"
						},
						{
							"name": "join1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EmpID as short,",
						"          EmpName as string,",
						"          DeptID as short,",
						"          Salary as short,",
						"          Bonus as short,",
						"          Gender as string,",
						"          Country as string,",
						"          City as string,",
						"          DOJ as string,",
						"          Company as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     ignoreNoFilesFound: false) ~> emp",
						"source(output(",
						"          DeptID as short,",
						"          DeptName as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     ignoreNoFilesFound: false) ~> dept",
						"emp aggregate(groupBy(DeptID),",
						"     TotalEmployeesbyDeptID = count(EmpID)) ~> aggregate1",
						"emp, dept join(emp@DeptID == dept@DeptID,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1",
						"join1 sink(allowSchemaDrift: true,",
						"     validateSchema: true,",
						"     partitionFileNames:['JoinSinkOutput_fromNewBranch.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          EmpID,",
						"          EmpName,",
						"          DeptID = emp@DeptID,",
						"          DeptName,",
						"          Salary,",
						"          Bonus,",
						"          Gender,",
						"          Country,",
						"          City,",
						"          DOJ,",
						"          Company",
						"     ),",
						"     partitionBy('hash', 1)) ~> joinsink",
						"aggregate1 sink(allowSchemaDrift: true,",
						"     validateSchema: true,",
						"     partitionFileNames:['AggregateSinkOutput_fromNewBranch.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          DeptID,",
						"          TotalEmployeesbyDeptID",
						"     ),",
						"     partitionBy('hash', 1)) ~> aggregatesink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Parametrizedataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_inputemp_sample",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_sinkoutput2_csv",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "filter1"
						}
					],
					"scriptLines": [
						"parameters{",
						"     dep_param as integer",
						"}",
						"source(output(",
						"          EmpID as short,",
						"          EmpName as string,",
						"          DeptID as short,",
						"          Salary as short,",
						"          Bonus as short,",
						"          Gender as string,",
						"          Country as string,",
						"          City as string,",
						"          DOJ as string,",
						"          Company as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 filter(DeptID==$dep_param) ~> filter1",
						"filter1 sink(allowSchemaDrift: true,",
						"     validateSchema: true,",
						"     partitionFileNames:['Parametrize_Dept_Output.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/ParseTransformation')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_azuresqldb1105",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_jsonoutput3",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "ParseSkills"
						},
						{
							"name": "ParseAddress"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          empname as string,",
						"          Skills as string,",
						"          emp_address as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> source1",
						"source1 parse(ParseSkills = Skills ? (skill1 as string,",
						"          skill2 as string,",
						"          skill3 as string),",
						"     format: 'delimited',",
						"     columnNamesAsHeader: false,",
						"     columnDelimiter: '|',",
						"     nullValue: '') ~> ParseSkills",
						"ParseSkills parse(ParseAddress = emp_address ? (city as string,",
						"          country as string,",
						"          Zipcode as string),",
						"     format: 'json',",
						"     documentForm: 'singleDocument') ~> ParseAddress",
						"ParseAddress sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['ParseSkills_Address_Output.json'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          empid,",
						"          empname,",
						"          Skill1 = ParseSkills.skill1,",
						"          Skill2 = ParseSkills.skill2,",
						"          Skill3 = ParseSkills.skill3,",
						"          City = ParseAddress.city,",
						"          Country = ParseAddress.country,",
						"          Zipcode = ParseAddress.Zipcode",
						"     ),",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Pivot')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_inputemp_sample",
								"type": "DatasetReference"
							},
							"name": "emp"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_sinkoutput2_csv",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "pivot"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EmpID as short,",
						"          EmpName as string,",
						"          DeptID as short,",
						"          Salary as short,",
						"          Bonus as short,",
						"          Gender as string,",
						"          Country as string,",
						"          City as string,",
						"          DOJ as string,",
						"          Company as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     ignoreNoFilesFound: false) ~> emp",
						"emp pivot(groupBy(DeptID),",
						"     pivotBy(Gender),",
						"     Employees = count(EmpID),",
						"     columnNaming: '$V_$N',",
						"     lateral: true) ~> pivot",
						"pivot sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Pivot_Outputsink.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Rank_DenseRank')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_inputemp_sample",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_sinkoutput2_csv",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "Rank"
						},
						{
							"name": "DenseRank"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EmpID as short,",
						"          EmpName as string,",
						"          DeptID as short,",
						"          Salary as short,",
						"          Bonus as short,",
						"          Gender as string,",
						"          Country as string,",
						"          City as string,",
						"          DOJ as string,",
						"          Company as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 rank(desc(Salary, true),",
						"     caseInsensitive: true,",
						"     output(Rank as long)) ~> Rank",
						"Rank rank(desc(Salary, true),",
						"     caseInsensitive: true,",
						"     output(DenseRank as long),",
						"     dense: true) ~> DenseRank",
						"DenseRank sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Rank&DenseRank_Output.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          EmpID,",
						"          EmpName,",
						"          DeptID,",
						"          Bonus,",
						"          Gender,",
						"          Country,",
						"          City,",
						"          DOJ,",
						"          Company,",
						"          Salary,",
						"          Rank,",
						"          DenseRank",
						"     ),",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/SchemaDrift')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_input_emp_DriftSchema",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_sinkoutput2_csv",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          name as string,",
						"          country as string,",
						"          department as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     ignoreNoFilesFound: false,",
						"     preferredIntegralType: 'integer') ~> source1",
						"source1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['DriftSchema_Output.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Stringify')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_jsoninput_1108",
								"type": "DatasetReference"
							},
							"name": "empjsonsrc"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_outputjson",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "stringify1"
						},
						{
							"name": "derivedColumn1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Emp_details as (id as string, name as string, Skills as string[], Address as (State as string, Country as string, Zipcode as string), Contact as (Phone as string, Email as string))[]",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     ignoreNoFilesFound: false,",
						"     documentForm: 'singleDocument') ~> empjsonsrc",
						"empjsonsrc stringify(AddressStringify = Emp_details.Address ? string,",
						"          ContactStringify = Emp_details.Contact ? string,",
						"     format: 'json') ~> stringify1",
						"stringify1 derive(address = toString(AddressStringify),",
						"          contact = toString(ContactStringify)) ~> derivedColumn1",
						"derivedColumn1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['stringify_output.json'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          Emp_details,",
						"          AddressStringify,",
						"          ContactStringify",
						"     ),",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/SurrogateKey')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_inputemp_sample",
								"type": "DatasetReference"
							},
							"name": "emp"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_sinkoutput2_csv",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "surrogateKey1"
						},
						{
							"name": "select1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EmpID as short,",
						"          EmpName as string,",
						"          DeptID as short,",
						"          Salary as short,",
						"          Bonus as short,",
						"          Gender as string,",
						"          Country as string,",
						"          City as string,",
						"          DOJ as string,",
						"          Company as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     ignoreNoFilesFound: false) ~> emp",
						"emp keyGenerate(output(EmpSurrogateKey as long),",
						"     startAt: 1L,",
						"     stepValue: 4L) ~> surrogateKey1",
						"surrogateKey1 select(mapColumn(",
						"          EmpSurrogateKey,",
						"          EmpName,",
						"          DeptID",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1 sink(allowSchemaDrift: true,",
						"     validateSchema: true,",
						"     partitionFileNames:['SurrogateKey_Output.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/UDF')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "userdefinedfunction",
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_inputemp_sample",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_sinkoutput3",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "derivedColumn1"
						}
					],
					"udfLibraries": [
						{
							"referenceName": "gender_df",
							"type": "DataFlowReference"
						},
						{
							"referenceName": "emp_grade",
							"type": "DataFlowReference"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EmpID as short,",
						"          EmpName as string,",
						"          DeptID as short,",
						"          Salary as short,",
						"          Bonus as short,",
						"          Gender as string,",
						"          Country as string,",
						"          City as string,",
						"          DOJ as string,",
						"          Company as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 derive(Gender_intvalue = toInteger(gender_values_in_integer(Gender)),",
						"          emp_grade = toString(emp_grade(Salary))) ~> derivedColumn1",
						"derivedColumn1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          DeptID as string,",
						"          DeptName as string",
						"     ),",
						"     partitionFileNames:['UDF_output.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/UnPivot_1')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_unpivot",
								"type": "DatasetReference"
							},
							"name": "POvendor"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_sinkoutput2_csv",
								"type": "DatasetReference"
							},
							"name": "UnPivotSink"
						}
					],
					"transformations": [
						{
							"name": "unpivot1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          PO as short,",
						"          Vendor as string,",
						"          Apple as short,",
						"          Pear as short,",
						"          Orange as short,",
						"          Mango as short",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     ignoreNoFilesFound: false) ~> POvendor",
						"POvendor unpivot(output(",
						"          Fruits as string,",
						"          Qty as short",
						"     ),",
						"     ungroupBy(PO,",
						"          Vendor),",
						"     lateral: false,",
						"     ignoreNullPivots: false) ~> unpivot1",
						"unpivot1 sink(allowSchemaDrift: true,",
						"     validateSchema: true,",
						"     partitionFileNames:['UnPivot_1_SinkOutput.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> UnPivotSink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/UnPivot_2')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_inputemp_sample",
								"type": "DatasetReference"
							},
							"name": "emp"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_sinkoutput2_csv",
								"type": "DatasetReference"
							},
							"name": "UnpivotSink"
						}
					],
					"transformations": [
						{
							"name": "pivot"
						},
						{
							"name": "unpivot1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EmpID as short,",
						"          EmpName as string,",
						"          DeptID as short,",
						"          Salary as short,",
						"          Bonus as short,",
						"          Gender as string,",
						"          Country as string,",
						"          City as string,",
						"          DOJ as string,",
						"          Company as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     ignoreNoFilesFound: false) ~> emp",
						"emp pivot(groupBy(DeptID),",
						"     pivotBy(Gender),",
						"     Employees = count(EmpID),",
						"     columnNaming: '$V_$N',",
						"     lateral: true) ~> pivot",
						"pivot unpivot(output(",
						"          Employees as long,",
						"          Total as long",
						"     ),",
						"     ungroupBy(DeptID),",
						"     lateral: true,",
						"     ignoreNullPivots: false) ~> unpivot1",
						"unpivot1 sink(allowSchemaDrift: true,",
						"     validateSchema: true,",
						"     partitionFileNames:['Unpivot_2_Outputsink.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> UnpivotSink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Union')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_marketingempcsv",
								"type": "DatasetReference"
							},
							"name": "Marketingemp"
						},
						{
							"dataset": {
								"referenceName": "ds_accountempcsv",
								"type": "DatasetReference"
							},
							"name": "accountemp"
						},
						{
							"dataset": {
								"referenceName": "ds_salesempcsv",
								"type": "DatasetReference"
							},
							"name": "salesemp"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_sinkoutput_csv",
								"type": "DatasetReference"
							},
							"name": "accountmarketingsalesemployees"
						}
					],
					"transformations": [
						{
							"name": "marketingaccountsalesemployees"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EmpID as short,",
						"          EmpName as string,",
						"          DeptID as short,",
						"          Salary as short,",
						"          Bonus as short,",
						"          Gender as string,",
						"          Country as string,",
						"          City as string,",
						"          DOJ as string,",
						"          Company as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     ignoreNoFilesFound: false) ~> Marketingemp",
						"source(output(",
						"          EmpID as short,",
						"          EmpName as string,",
						"          DeptID as short,",
						"          Salary as short,",
						"          Bonus as short,",
						"          Gender as string,",
						"          Country as string,",
						"          City as string,",
						"          DOJ as string,",
						"          Company as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     ignoreNoFilesFound: false) ~> accountemp",
						"source(output(",
						"          EmpID as short,",
						"          EmpName as string,",
						"          DeptID as short,",
						"          Salary as short,",
						"          Bonus as short,",
						"          Gender as string,",
						"          Country as string,",
						"          City as string,",
						"          DOJ as string,",
						"          Company as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     ignoreNoFilesFound: false) ~> salesemp",
						"accountemp, Marketingemp, salesemp union(byName: true)~> marketingaccountsalesemployees",
						"marketingaccountsalesemployees sink(allowSchemaDrift: true,",
						"     validateSchema: true,",
						"     partitionFileNames:['Unionoutput(accountmarketingsales_emp).csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          EmpID,",
						"          EmpName,",
						"          DeptID,",
						"          Salary,",
						"          Bonus,",
						"          Gender,",
						"          Country,",
						"          City,",
						"          DOJ,",
						"          Company",
						"     ),",
						"     partitionBy('hash', 1)) ~> accountmarketingsalesemployees"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/aggregate')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_inputemp_sample",
								"type": "DatasetReference"
							},
							"name": "emp"
						},
						{
							"dataset": {
								"referenceName": "ds_inputdept_sample",
								"type": "DatasetReference"
							},
							"name": "dept"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_sinkoutput_csv",
								"type": "DatasetReference"
							},
							"name": "sink1",
							"rejectedDataLinkedService": {
								"referenceName": "ls_adlsgen2_2510",
								"type": "LinkedServiceReference"
							}
						}
					],
					"transformations": [
						{
							"name": "aggregate1"
						},
						{
							"name": "join1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EmpID as short,",
						"          EmpName as string,",
						"          DeptID as short,",
						"          Salary as short,",
						"          Bonus as short,",
						"          Gender as string,",
						"          Country as string,",
						"          City as string,",
						"          DOJ as string,",
						"          Company as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     ignoreNoFilesFound: false) ~> emp",
						"source(output(",
						"          DeptID as short,",
						"          DeptName as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     ignoreNoFilesFound: false) ~> dept",
						"emp aggregate(groupBy(DeptID),",
						"     {Total Employee} = count(EmpID)) ~> aggregate1",
						"aggregate1, dept join(aggregate1@DeptID == dept@DeptID,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1",
						"join1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['aggregateresultbydept.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          DeptID = dept@DeptID,",
						"          DeptName,",
						"          {Total Employee}",
						"     ),",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_flowletuse')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_empflowletcsv",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_sinkoutput3",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "flowlet1",
							"flowlet": {
								"referenceName": "flowlet1",
								"type": "DataFlowReference",
								"parameters": {}
							}
						}
					],
					"scriptLines": [
						"source(output(",
						"          id as integer,",
						"          name as string,",
						"          gender as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 compose(mapColumn(",
						"          id,",
						"          name,",
						"          gender",
						"     ),",
						"     composition: 'flowlet1') ~> flowlet1@(output1)",
						"flowlet1@output1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          DeptID as string,",
						"          DeptName as string",
						"     ),",
						"     partitionFileNames:['flowletoutput.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/derived')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_inputemp_sample",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_sinkoutput_csv",
								"type": "DatasetReference"
							},
							"name": "DerivedSink"
						}
					],
					"transformations": [
						{
							"name": "derivedColumn1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EmpID as short,",
						"          EmpName as string,",
						"          DeptID as short,",
						"          Salary as short,",
						"          Bonus as short,",
						"          Gender as string,",
						"          Country as string,",
						"          City as string,",
						"          DOJ as string,",
						"          Company as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 derive(Country = upper(Country),",
						"          Grade = iif(Salary>1500,'Grade-A','Grade-B')) ~> derivedColumn1",
						"derivedColumn1 sink(allowSchemaDrift: true,",
						"     validateSchema: true,",
						"     partitionFileNames:['DerivedSink.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          EmpID,",
						"          EmpName,",
						"          DeptID,",
						"          Salary,",
						"          Bonus,",
						"          Gender,",
						"          Country,",
						"          City,",
						"          DOJ,",
						"          Company,",
						"          GradeofEmp = Grade",
						"     ),",
						"     partitionBy('hash', 1)) ~> DerivedSink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/exists')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_inputemp_sample",
								"type": "DatasetReference"
							},
							"name": "emp"
						},
						{
							"dataset": {
								"referenceName": "ds_inputdept_sample",
								"type": "DatasetReference"
							},
							"name": "dept"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_sinkoutput_csv",
								"type": "DatasetReference"
							},
							"name": "existsoutput"
						}
					],
					"transformations": [
						{
							"name": "exists"
						},
						{
							"name": "join1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EmpID as short,",
						"          EmpName as string,",
						"          DeptID as short,",
						"          Salary as short,",
						"          Bonus as short,",
						"          Gender as string,",
						"          Country as string,",
						"          City as string,",
						"          DOJ as string,",
						"          Company as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     ignoreNoFilesFound: false) ~> emp",
						"source(output(",
						"          DeptID as short,",
						"          DeptName as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     ignoreNoFilesFound: false) ~> dept",
						"emp, dept exists(emp@DeptID == dept@DeptID,",
						"     negate:false,",
						"     broadcast: 'auto')~> exists",
						"exists, dept join(emp@DeptID == dept@DeptID,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1",
						"join1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['Exists_output.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          EmpID,",
						"          EmpName,",
						"          DeptID = emp@DeptID,",
						"          DeptName,",
						"          Salary,",
						"          Bonus,",
						"          Gender,",
						"          Country,",
						"          City,",
						"          DOJ,",
						"          Company",
						"     ),",
						"     partitionBy('hash', 1)) ~> existsoutput"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/filter')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_inputemp_sample",
								"type": "DatasetReference"
							},
							"name": "empsource"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_sinkoutput_csv",
								"type": "DatasetReference"
							},
							"name": "Marketingempsink",
							"rejectedDataLinkedService": {
								"referenceName": "ls_adlsgen2_2510",
								"type": "LinkedServiceReference"
							}
						}
					],
					"transformations": [
						{
							"name": "filter"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EmpID as short,",
						"          EmpName as string,",
						"          DeptID as short,",
						"          Salary as short,",
						"          Bonus as short,",
						"          Gender as string,",
						"          Country as string,",
						"          City as string,",
						"          DOJ as string,",
						"          Company as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     ignoreNoFilesFound: false) ~> empsource",
						"empsource filter(DeptID==30) ~> filter",
						"filter sink(allowSchemaDrift: true,",
						"     validateSchema: true,",
						"     partitionFileNames:['filter_output.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          EmpID,",
						"          EmpName,",
						"          DeptID,",
						"          Salary,",
						"          Bonus,",
						"          Gender,",
						"          Country,",
						"          City,",
						"          DOJ,",
						"          Company",
						"     ),",
						"     partitionBy('hash', 1)) ~> Marketingempsink"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/join')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_input_excel_emp",
								"type": "DatasetReference"
							},
							"name": "emp"
						},
						{
							"dataset": {
								"referenceName": "ds_input_excel_dept",
								"type": "DatasetReference"
							},
							"name": "dept"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_sinkoutput_csv",
								"type": "DatasetReference"
							},
							"name": "sink1",
							"rejectedDataLinkedService": {
								"referenceName": "ls_adlsgen2_2510",
								"type": "LinkedServiceReference"
							}
						}
					],
					"transformations": [
						{
							"name": "Derivedcolumns",
							"description": "Autogenerated by data preview actions"
						},
						{
							"name": "join"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EmpID as short,",
						"          EmpName as string,",
						"          DeptID as short,",
						"          Salary as short,",
						"          Bonus as short,",
						"          Gender as string,",
						"          City as string,",
						"          DOJ as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     ignoreNoFilesFound: false,",
						"     dateFormats: ['MM/dd/yyyy'],",
						"     timestampFormats: ['MM/dd/yyyy HH:mm:ss'],",
						"     preferredIntegralType: 'short',",
						"     preferredFractionalType: 'float',",
						"     booleanFormat: ['True', 'False']) ~> emp",
						"source(output(",
						"          DeptID as short,",
						"          DeptName as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     ignoreNoFilesFound: false) ~> dept",
						"emp derive(DOJ = toDate(DOJ),",
						"          Class = iif(Salary>2000, 'I', 'II')) ~> Derivedcolumns",
						"Derivedcolumns, dept join(emp@DeptID == dept@DeptID,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join",
						"join sink(allowSchemaDrift: true,",
						"     validateSchema: true,",
						"     partitionFileNames:['join_output_deptempsink.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          EmpID,",
						"          EmpName,",
						"          DeptID = emp@DeptID,",
						"          DeptName,",
						"          Salary,",
						"          Class,",
						"          Bonus,",
						"          Gender,",
						"          City,",
						"          DOJ",
						"     ),",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/not_exists')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_inputemp_sample",
								"type": "DatasetReference"
							},
							"name": "emp"
						},
						{
							"dataset": {
								"referenceName": "ds_inputdept_sample",
								"type": "DatasetReference"
							},
							"name": "dept"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_sinkoutput_csv",
								"type": "DatasetReference"
							},
							"name": "Notexistsoutput"
						}
					],
					"transformations": [
						{
							"name": "Notexists"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EmpID as short,",
						"          EmpName as string,",
						"          DeptID as short,",
						"          Salary as short,",
						"          Bonus as short,",
						"          Gender as string,",
						"          Country as string,",
						"          City as string,",
						"          DOJ as string,",
						"          Company as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> emp",
						"source(output(",
						"          DeptID as short,",
						"          DeptName as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     inferDriftedColumnTypes: true,",
						"     ignoreNoFilesFound: false) ~> dept",
						"emp, dept exists(emp@DeptID == dept@DeptID,",
						"     negate:true,",
						"     broadcast: 'auto')~> Notexists",
						"Notexists sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['NotExists_output.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          EmpID,",
						"          EmpName,",
						"          DeptID,",
						"          Salary,",
						"          Bonus,",
						"          Gender,",
						"          Country,",
						"          City,",
						"          DOJ,",
						"          Company",
						"     ),",
						"     partitionBy('hash', 1)) ~> Notexistsoutput"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/pq1_GroupBy')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "WranglingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"name": "ds_inputemp_sample",
							"script": "source(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tinferDriftedColumnTypes: true,\n\tignoreNoFilesFound: false) ~> ds_inputemp_sample",
							"dataset": {
								"referenceName": "ds_inputemp_sample",
								"type": "DatasetReference"
							}
						},
						{
							"name": "ds_inputdept_sample",
							"script": "source(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tinferDriftedColumnTypes: true,\n\tignoreNoFilesFound: false,\n\tpartitionBy('hash', 1)) ~> ds_inputdept_sample",
							"dataset": {
								"referenceName": "ds_inputdept_sample",
								"type": "DatasetReference"
							}
						}
					],
					"script": "section Section1;\r\nshared ds_inputemp_sample = let AdfDoc = AzureStorage.DataLakeContents(\"https://sspadls2410.dfs.core.windows.net/input/emp_sample.csv\"),Csv = Csv.Document(AdfDoc, [Delimiter = \",\", Encoding = TextEncoding.Utf8, QuoteStyle = QuoteStyle.Csv]), PromotedHeaders = Table.PromoteHeaders(Csv, [PromoteAllScalars = true]) in  PromotedHeaders;\r\nshared ds_inputdept_sample = let AdfDoc = AzureStorage.DataLakeContents(\"https://sspadls2410.dfs.core.windows.net/input/Dept_sample.csv\"),Csv = Csv.Document(AdfDoc, [Delimiter = \",\", Encoding = TextEncoding.Utf8, QuoteStyle = QuoteStyle.Csv]), PromotedHeaders = Table.PromoteHeaders(Csv, [PromoteAllScalars = true]) in  PromotedHeaders;\r\nshared UserQuery = let Source = #\"ds_inputemp_sample\",\r\n  #\"Grouped rows\" = Table.Group(Source, {\"DeptID\"}, {{\"TotalEmpbyDept\", each Table.RowCount(_), Int64.Type}}),\r\n  #\"Sorted rows\" = Table.Sort(#\"Grouped rows\", {{\"DeptID\", Order.Descending}}) in #\"Sorted rows\";\r\n",
					"documentLocale": "en-us"
				}
			},
			"dependsOn": []
		}
	]
}